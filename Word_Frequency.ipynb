{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ce2b5a",
   "metadata": {},
   "source": [
    "# Making a word frequencies\n",
    "\n",
    "Here we want to create a word frequencies. The word frequencies means to know how many times a word appears in a text. The final result will be stored in a dictionary of words. The dataset is in the [NLTK](https://www.nltk.org/) library which contains both positive and negative tweets.\n",
    "To find the frequencies we need to follow these steps below:\n",
    "\n",
    "## Plan:\n",
    "    1- We need to create labels as 1 and 0 with equal length of positive and negative tweets.\n",
    "\n",
    "    2- Process the tweets by the process function to remove unwanted charactors, tokenizing, and stemming the words. \n",
    "\n",
    "    3- Join the list of tokens for each tweets. \n",
    "\n",
    "    4- Identify the words which are in positive and negative tweet and label them as 1 and 0 for positive and negative tweets, respectively. And find the frequency of repeated words. \n",
    "\n",
    " \n",
    "\n",
    "In the first step we need to import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c8b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc2135",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffcda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_twt = twitter_samples.strings('positive_tweets.json')\n",
    "neg_twt = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "twts = pos_twt+neg_twt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6687b5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(twts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d089413",
   "metadata": {},
   "source": [
    "## Step: 1. Create the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fd1fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.append( np.ones(len(pos_twt)), np.zeros(len(neg_twt)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dfe8a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e8bba",
   "metadata": {},
   "source": [
    "## Step: 2\n",
    "After importing the libraries we need to build up a function which counts the number. Before to know the frequencies of the words we need to process the tweets. To do so, the process functions will help us here. The results of processed tweet will be stored in the ***processed_twts*** list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c47c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "stop_wrds_en = stopwords.words('english')\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \n",
    "    \n",
    "    # Instantiate stemming class\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    tweet = re.sub(r'^RT[\\s]+','', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tweet = re.sub(r'@', '', tweet)\n",
    "    tweet = re.sub(r'@', '', tweet)\n",
    "    tweet = re.sub(r'\\$\\w*','', tweet)\n",
    "    \n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    twt_tokened = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    clean_twt = []\n",
    "    \n",
    "    for word in twt_tokened:\n",
    "        if (word not in stop_wrds_en and word not in string.punctuation):\n",
    "            clean_twt.append(word)\n",
    "    \n",
    "    stemed_twt = []\n",
    "    for word in clean_twt:\n",
    "        word_stemmed = stemmer.stem(word)\n",
    "        stemed_twt.append(word_stemmed)\n",
    "    \n",
    "    return stemed_twt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c664c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_twts = []\n",
    "\n",
    "for tweet in twts:\n",
    "    processed_twts.append(process_tweet(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ee74c",
   "metadata": {},
   "source": [
    "The build frequency functions counts the number of times the word repeats in both positive and negatvie tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d9f6e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last processed tweet\n",
      " ['eawoman', 'hull', 'support', 'expect', 'misser', 'week', ':-(']\n",
      "The first processed tweet\n",
      " ['followfriday', 'france_int', 'pkuchli', '57', 'milipol_pari', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "print('The last processed tweet\\n',processed_twts[len(processed_twts)-1])\n",
    "\n",
    "print('The first processed tweet\\n', processed_twts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0526591",
   "metadata": {},
   "source": [
    "## Step: 3\n",
    "Since the processed tweets has the list of words we need to join them again to have a sentence for each of tweets. ***processed_twts2*** has the sentence of each tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2953f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_twts2 = []\n",
    "\n",
    "for lst_tokens in processed_twts:\n",
    "    processed_twts2.append( ' '.join(lst_tokens) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b18b9c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lamb 2ja hey jame odd :/ pleas call contact centr 02392441234 abl assist :) mani thank'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_twts2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1a953",
   "metadata": {},
   "source": [
    "## Step: 4\n",
    "Find the frequency of words in + and - tweets. The result is stored in ***freqs*** dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50250bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(tweets, labels):\n",
    "    ylist = np.squeeze(labels).tolist()\n",
    "    \n",
    "    freqs = {}\n",
    "    \n",
    "    for y, tweet in zip(ylist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            \n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a154fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freqs(processed_twts2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1fb55",
   "metadata": {},
   "source": [
    "Let's see the frequency list of words of + and - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f107ffb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('followfriday', 1.0): 25,\n",
       " ('france_int', 1.0): 1,\n",
       " ('pkuchli', 1.0): 1,\n",
       " ('57', 1.0): 2,\n",
       " ('milipol_pari', 1.0): 1,\n",
       " ('top', 1.0): 32,\n",
       " ('engag', 1.0): 7,\n",
       " ('member', 1.0): 16,\n",
       " ('commun', 1.0): 33,\n",
       " ('week', 1.0): 84,\n",
       " (':)', 1.0): 3568,\n",
       " ('lamb', 1.0): 1,\n",
       " ('2ja', 1.0): 1,\n",
       " ('hey', 1.0): 76,\n",
       " ('jame', 1.0): 7,\n",
       " ('odd', 1.0): 2,\n",
       " (':/', 1.0): 5,\n",
       " ('plea', 1.0): 97,\n",
       " ('call', 1.0): 37,\n",
       " ('contact', 1.0): 7,\n",
       " ('centr', 1.0): 2,\n",
       " ('02392441234', 1.0): 1,\n",
       " ('abl', 1.0): 8,\n",
       " ('assist', 1.0): 1,\n",
       " ('mani', 1.0): 33,\n",
       " ('thank', 1.0): 621,\n",
       " ('despiteoffici', 1.0): 1,\n",
       " ('listen', 1.0): 16,\n",
       " ('last', 1.0): 47,\n",
       " ('night', 1.0): 70,\n",
       " ('bleed', 1.0): 2,\n",
       " ('amaz', 1.0): 51,\n",
       " ('track', 1.0): 5,\n",
       " ('scotland', 1.0): 2,\n",
       " ('97side', 1.0): 1,\n",
       " ('congrat', 1.0): 21,\n",
       " ('yeaaah', 1.0): 1,\n",
       " ('yipppi', 1.0): 1,\n",
       " ('accnt', 1.0): 2,\n",
       " ('verifi', 1.0): 2,\n",
       " ('rqst', 1.0): 1,\n",
       " ('succeed', 1.0): 1,\n",
       " ('got', 1.0): 69,\n",
       " ('blue', 1.0): 9,\n",
       " ('tick', 1.0): 1,\n",
       " ('mark', 1.0): 2,\n",
       " ('fb', 1.0): 6,\n",
       " ('profil', 1.0): 2,\n",
       " ('15', 1.0): 9,\n",
       " ('day', 1.0): 246,\n",
       " ('bhaktisb', 1.0): 17,\n",
       " ('pallaviruhail', 1.0): 8,\n",
       " ('one', 1.0): 129,\n",
       " ('irresist', 1.0): 2,\n",
       " ('flipkartfashionfriday', 1.0): 17,\n",
       " ('like', 1.0): 233,\n",
       " ('keep', 1.0): 68,\n",
       " ('love', 1.0): 400,\n",
       " ('custom', 1.0): 4,\n",
       " ('wait', 1.0): 69,\n",
       " ('long', 1.0): 36,\n",
       " ('hope', 1.0): 141,\n",
       " ('enjoy', 1.0): 75,\n",
       " ('happi', 1.0): 211,\n",
       " ('friday', 1.0): 117,\n",
       " ('lwwf', 1.0): 1,\n",
       " ('impatientraid', 1.0): 1,\n",
       " ('second', 1.0): 11,\n",
       " ('thought', 1.0): 30,\n",
       " ('‚Äô', 1.0): 21,\n",
       " ('enough', 1.0): 18,\n",
       " ('time', 1.0): 127,\n",
       " ('dd', 1.0): 1,\n",
       " ('new', 1.0): 143,\n",
       " ('short', 1.0): 7,\n",
       " ('enter', 1.0): 9,\n",
       " ('system', 1.0): 2,\n",
       " ('sheep', 1.0): 1,\n",
       " ('must', 1.0): 18,\n",
       " ('buy', 1.0): 11,\n",
       " ('jgh', 1.0): 4,\n",
       " ('go', 1.0): 148,\n",
       " ('bayan', 1.0): 1,\n",
       " (':d', 1.0): 629,\n",
       " ('bye', 1.0): 7,\n",
       " ('act', 1.0): 8,\n",
       " ('mischiev', 1.0): 1,\n",
       " ('etl', 1.0): 1,\n",
       " ('layer', 1.0): 1,\n",
       " ('in-hou', 1.0): 1,\n",
       " ('wareh', 1.0): 2,\n",
       " ('app', 1.0): 16,\n",
       " ('katamari', 1.0): 1,\n",
       " ('well', 1.0): 81,\n",
       " ('‚Ä¶', 1.0): 38,\n",
       " ('name', 1.0): 18,\n",
       " ('impli', 1.0): 1,\n",
       " (':p', 1.0): 138,\n",
       " ('wncer', 1.0): 1,\n",
       " ('1', 1.0): 153,\n",
       " ('defense_gouv', 1.0): 1,\n",
       " ('influenc', 1.0): 18,\n",
       " ('big', 1.0): 33,\n",
       " ('...', 1.0): 285,\n",
       " ('juici', 1.0): 3,\n",
       " ('selfi', 1.0): 12,\n",
       " ('mish', 1.0): 1,\n",
       " ('2361535', 1.0): 1,\n",
       " ('follow', 1.0): 381,\n",
       " ('jnlazt', 1.0): 62,\n",
       " ('jjulieredburn', 1.0): 1,\n",
       " ('perfect', 1.0): 24,\n",
       " ('alreadi', 1.0): 28,\n",
       " ('know', 1.0): 145,\n",
       " ('great', 1.0): 171,\n",
       " ('opportun', 1.0): 23,\n",
       " ('junior', 1.0): 2,\n",
       " ('triathlet', 1.0): 1,\n",
       " ('age', 1.0): 2,\n",
       " ('12', 1.0): 9,\n",
       " ('13', 1.0): 12,\n",
       " ('gatorad', 1.0): 1,\n",
       " ('seri', 1.0): 5,\n",
       " ('get', 1.0): 206,\n",
       " ('entri', 1.0): 4,\n",
       " ('lay', 1.0): 4,\n",
       " ('greet', 1.0): 5,\n",
       " ('card', 1.0): 8,\n",
       " ('rang', 1.0): 3,\n",
       " ('print', 1.0): 3,\n",
       " ('today', 1.0): 111,\n",
       " ('job', 1.0): 41,\n",
       " (':-)', 1.0): 692,\n",
       " ('friend', 1.0): 64,\n",
       " ('lunch', 1.0): 5,\n",
       " ('yummm', 1.0): 1,\n",
       " ('nostalgia', 1.0): 1,\n",
       " ('tb', 1.0): 2,\n",
       " ('ku', 1.0): 1,\n",
       " ('rookiesenpai', 1.0): 1,\n",
       " ('arcadest', 1.0): 1,\n",
       " ('id', 1.0): 8,\n",
       " ('conflict', 1.0): 1,\n",
       " ('help', 1.0): 41,\n",
       " ('screenshot', 1.0): 3,\n",
       " ('work', 1.0): 110,\n",
       " ('oohdawg', 1.0): 1,\n",
       " ('hi', 1.0): 173,\n",
       " ('liv', 1.0): 2,\n",
       " ('hello', 1.0): 59,\n",
       " ('need', 1.0): 78,\n",
       " ('someth', 1.0): 28,\n",
       " ('u', 1.0): 175,\n",
       " ('fm', 1.0): 2,\n",
       " ('twitter', 1.0): 29,\n",
       " ('‚Äî', 1.0): 27,\n",
       " ('sure', 1.0): 58,\n",
       " ('thing', 1.0): 69,\n",
       " ('dm', 1.0): 39,\n",
       " ('x', 1.0): 72,\n",
       " ('mbandscott', 1.0): 1,\n",
       " ('eric_fl', 1.0): 1,\n",
       " ('pointsolut', 1.0): 1,\n",
       " ('3', 1.0): 51,\n",
       " ('rossbreadmor', 1.0): 1,\n",
       " (\"i'v\", 1.0): 35,\n",
       " ('heard', 1.0): 9,\n",
       " ('four', 1.0): 5,\n",
       " ('season', 1.0): 9,\n",
       " ('pretti', 1.0): 20,\n",
       " ('dope', 1.0): 2,\n",
       " ('penthou', 1.0): 1,\n",
       " ('obv', 1.0): 1,\n",
       " ('gobigorgohom', 1.0): 1,\n",
       " ('fun', 1.0): 58,\n",
       " (\"y'all\", 1.0): 3,\n",
       " ('gculloti', 1.0): 5,\n",
       " ('87', 1.0): 8,\n",
       " ('yeah', 1.0): 47,\n",
       " ('suppo', 1.0): 7,\n",
       " ('lol', 1.0): 64,\n",
       " ('chat', 1.0): 13,\n",
       " ('bit', 1.0): 20,\n",
       " ('youth', 1.0): 19,\n",
       " ('tolajobjob', 1.0): 19,\n",
       " ('maphisa', 1.0): 1,\n",
       " ('301', 1.0): 1,\n",
       " ('üíÖüèΩ', 1.0): 1,\n",
       " ('üíã', 1.0): 2,\n",
       " ('seen', 1.0): 10,\n",
       " ('year', 1.0): 45,\n",
       " ('bosslog', 1.0): 1,\n",
       " ('amellywood', 1.0): 1,\n",
       " ('cw_arrow', 1.0): 1,\n",
       " ('arrowwrit', 1.0): 1,\n",
       " ('johngutierrez', 1.0): 1,\n",
       " ('rest', 1.0): 12,\n",
       " ('goe', 1.0): 7,\n",
       " ('quickli', 1.0): 3,\n",
       " ('bed', 1.0): 16,\n",
       " ('music', 1.0): 21,\n",
       " ('fix', 1.0): 10,\n",
       " ('dream', 1.0): 20,\n",
       " ('spiritu', 1.0): 1,\n",
       " ('ritual', 1.0): 1,\n",
       " ('festiv', 1.0): 8,\n",
       " ('n√©pal', 1.0): 1,\n",
       " ('begin', 1.0): 4,\n",
       " ('line-up', 1.0): 4,\n",
       " ('left', 1.0): 13,\n",
       " ('see', 1.0): 184,\n",
       " ('ke7zum', 1.0): 1,\n",
       " ('sarah', 1.0): 4,\n",
       " ('send', 1.0): 22,\n",
       " ('us', 1.0): 109,\n",
       " ('email', 1.0): 26,\n",
       " ('bitsybitdefender.com', 1.0): 1,\n",
       " (\"we'll\", 1.0): 20,\n",
       " ('asap', 1.0): 5,\n",
       " ('izzkamilhalda', 1.0): 1,\n",
       " ('kik', 1.0): 22,\n",
       " ('hatessuc', 1.0): 1,\n",
       " ('32429', 1.0): 1,\n",
       " ('kikm', 1.0): 1,\n",
       " ('lgbt', 1.0): 2,\n",
       " ('tinder', 1.0): 1,\n",
       " ('nsfw', 1.0): 1,\n",
       " ('akua', 1.0): 1,\n",
       " ('cumshot', 1.0): 1,\n",
       " ('kalinwhit', 1.0): 3,\n",
       " ('come', 1.0): 70,\n",
       " ('hou', 1.0): 7,\n",
       " ('nsn_supplement', 1.0): 1,\n",
       " ('effect', 1.0): 4,\n",
       " ('press', 1.0): 1,\n",
       " ('relea', 1.0): 11,\n",
       " ('distribut', 1.0): 1,\n",
       " ('result', 1.0): 2,\n",
       " ('link', 1.0): 18,\n",
       " ('remov', 1.0): 3,\n",
       " ('pressrelea', 1.0): 1,\n",
       " ('newsdistribut', 1.0): 1,\n",
       " ('bam', 1.0): 44,\n",
       " ('barsandmelodi', 1.0): 44,\n",
       " ('bestfriend', 1.0): 50,\n",
       " ('969horan696', 1.0): 44,\n",
       " ('lot', 1.0): 87,\n",
       " ('warsaw', 1.0): 44,\n",
       " ('<3', 1.0): 134,\n",
       " ('x46', 1.0): 1,\n",
       " ('everyon', 1.0): 58,\n",
       " ('watch', 1.0): 46,\n",
       " ('documentari', 1.0): 1,\n",
       " ('earthl', 1.0): 2,\n",
       " ('youtub', 1.0): 19,\n",
       " ('jamiefigsxx', 1.0): 1,\n",
       " ('michelbauza', 1.0): 1,\n",
       " ('invataonlin', 1.0): 1,\n",
       " ('support', 1.0): 27,\n",
       " ('buuut', 1.0): 1,\n",
       " ('oh', 1.0): 53,\n",
       " ('leisuremarkltd', 1.0): 1,\n",
       " ('noshandquaff', 1.0): 1,\n",
       " ('aktarislam', 1.0): 1,\n",
       " ('keanebrand', 1.0): 1,\n",
       " ('heritagesilv', 1.0): 1,\n",
       " ('look', 1.0): 138,\n",
       " ('forward', 1.0): 29,\n",
       " ('visit', 1.0): 30,\n",
       " ('next', 1.0): 48,\n",
       " ('letsgetmessi', 1.0): 1,\n",
       " ('jo', 1.0): 1,\n",
       " ('sehunshinedaili', 1.0): 1,\n",
       " ('make', 1.0): 99,\n",
       " ('feel', 1.0): 46,\n",
       " ('better', 1.0): 52,\n",
       " ('never', 1.0): 36,\n",
       " ('anyon', 1.0): 11,\n",
       " ('kpop', 1.0): 1,\n",
       " ('flesh', 1.0): 1,\n",
       " ('joyster', 1.0): 1,\n",
       " ('2012', 1.0): 2,\n",
       " ('cathstaincliff', 1.0): 1,\n",
       " ('good', 1.0): 238,\n",
       " ('girl', 1.0): 44,\n",
       " ('best', 1.0): 65,\n",
       " ('wish', 1.0): 37,\n",
       " ('_kimimi', 1.0): 1,\n",
       " ('reason', 1.0): 13,\n",
       " ('epic', 1.0): 2,\n",
       " ('soundtrack', 1.0): 1,\n",
       " ('aquadesigngroup', 1.0): 2,\n",
       " ('shout', 1.0): 12,\n",
       " ('ad', 1.0): 14,\n",
       " ('video', 1.0): 35,\n",
       " ('playlist', 1.0): 5,\n",
       " ('would', 1.0): 84,\n",
       " ('dear', 1.0): 17,\n",
       " ('jordan', 1.0): 1,\n",
       " ('firdoz', 1.0): 1,\n",
       " ('visitjordan', 1.0): 2,\n",
       " ('dannyprol', 1.0): 1,\n",
       " ('abnormal_ana', 1.0): 2,\n",
       " ('92', 1.0): 8,\n",
       " ('okay', 1.0): 39,\n",
       " ('sssniperwolf', 1.0): 1,\n",
       " ('fake', 1.0): 2,\n",
       " ('gameplay', 1.0): 2,\n",
       " (';)', 1.0): 27,\n",
       " ('haha', 1.0): 53,\n",
       " ('im', 1.0): 51,\n",
       " ('kid', 1.0): 18,\n",
       " ('stuff', 1.0): 13,\n",
       " ('dennislami', 1.0): 1,\n",
       " ('dicle_aygur', 1.0): 1,\n",
       " ('exactli', 1.0): 6,\n",
       " ('product', 1.0): 12,\n",
       " ('line', 1.0): 6,\n",
       " ('etsi', 1.0): 2,\n",
       " ('shop', 1.0): 16,\n",
       " ('check', 1.0): 52,\n",
       " ('peakyourmind', 1.0): 1,\n",
       " ('vacat', 1.0): 6,\n",
       " ('groovinshawn', 1.0): 1,\n",
       " ('recharg', 1.0): 1,\n",
       " ('normal', 1.0): 6,\n",
       " ('charger', 1.0): 2,\n",
       " ('france_espana', 1.0): 1,\n",
       " ('reglisse_menth', 1.0): 1,\n",
       " ('cci_int', 1.0): 1,\n",
       " ('asleep', 1.0): 9,\n",
       " ('talk', 1.0): 45,\n",
       " ('sooo', 1.0): 6,\n",
       " ('someon', 1.0): 34,\n",
       " ('text', 1.0): 18,\n",
       " ('brynybrath', 1.0): 1,\n",
       " ('smallcappi', 1.0): 1,\n",
       " ('ye', 1.0): 77,\n",
       " ('bet', 1.0): 6,\n",
       " (\"he'll\", 1.0): 4,\n",
       " ('fit', 1.0): 3,\n",
       " ('hear', 1.0): 33,\n",
       " ('speech', 1.0): 1,\n",
       " ('piti', 1.0): 3,\n",
       " ('green', 1.0): 3,\n",
       " ('garden', 1.0): 7,\n",
       " ('midnight', 1.0): 1,\n",
       " ('sun', 1.0): 6,\n",
       " ('beauti', 1.0): 52,\n",
       " ('canal', 1.0): 1,\n",
       " ('dasvidaniya', 1.0): 1,\n",
       " ('till', 1.0): 18,\n",
       " ('keithrparson', 1.0): 1,\n",
       " ('scout', 1.0): 1,\n",
       " ('sg', 1.0): 1,\n",
       " ('futur', 1.0): 13,\n",
       " ('wlan', 1.0): 1,\n",
       " ('pro', 1.0): 5,\n",
       " ('confer', 1.0): 1,\n",
       " ('asia', 1.0): 1,\n",
       " ('cecilie_hel', 1.0): 1,\n",
       " ('420evilangel', 1.0): 1,\n",
       " ('wazimotomet', 1.0): 1,\n",
       " ('durooo', 1.0): 1,\n",
       " ('spigranti', 1.0): 1,\n",
       " ('chang', 1.0): 24,\n",
       " ('lollipop', 1.0): 1,\n",
       " ('üç≠', 1.0): 1,\n",
       " ('nez', 1.0): 1,\n",
       " ('agnezmo', 1.0): 1,\n",
       " ('littlemix', 1.0): 2,\n",
       " ('elemaaan', 1.0): 1,\n",
       " ('oley', 1.0): 1,\n",
       " ('cowokaddict', 1.0): 1,\n",
       " ('mama', 1.0): 1,\n",
       " ('stand', 1.0): 8,\n",
       " ('stronger', 1.0): 1,\n",
       " ('macatangayapril', 1.0): 1,\n",
       " ('tk_kjk_kndr', 1.0): 1,\n",
       " ('boukendream', 1.0): 1,\n",
       " ('god', 1.0): 22,\n",
       " ('misti', 1.0): 1,\n",
       " ('babi', 1.0): 21,\n",
       " ('cute', 1.0): 26,\n",
       " ('carcassdrop', 1.0): 1,\n",
       " ('woohoo', 1.0): 3,\n",
       " (\"can't\", 1.0): 43,\n",
       " ('sign', 1.0): 11,\n",
       " ('yet', 1.0): 13,\n",
       " ('still', 1.0): 48,\n",
       " ('think', 1.0): 63,\n",
       " ('mka', 1.0): 5,\n",
       " ('liam', 1.0): 8,\n",
       " ('access', 1.0): 3,\n",
       " ('syuhxdxtengku', 1.0): 1,\n",
       " ('welcom', 1.0): 73,\n",
       " ('stat', 1.0): 60,\n",
       " ('arriv', 1.0): 67,\n",
       " ('unfollow', 1.0): 63,\n",
       " ('via', 1.0): 69,\n",
       " ('sluttywif', 1.0): 1,\n",
       " ('2', 1.0): 80,\n",
       " ('surpri', 1.0): 10,\n",
       " ('figur', 1.0): 5,\n",
       " ('murtishaw', 1.0): 1,\n",
       " ('aqui_fr', 1.0): 1,\n",
       " ('frtechstartup', 1.0): 1,\n",
       " ('happybirthdayemilybett', 1.0): 1,\n",
       " ('emilybett', 1.0): 8,\n",
       " ('sweet', 1.0): 19,\n",
       " ('talent', 1.0): 5,\n",
       " ('plan', 1.0): 27,\n",
       " ('drain', 1.0): 1,\n",
       " ('x123456789tine', 1.0): 2,\n",
       " ('5sos_fahupd', 1.0): 3,\n",
       " ('gotta', 1.0): 5,\n",
       " ('timezon', 1.0): 1,\n",
       " ('parent', 1.0): 5,\n",
       " ('proud', 1.0): 12,\n",
       " ('least', 1.0): 16,\n",
       " ('mayb', 1.0): 18,\n",
       " ('sometim', 1.0): 13,\n",
       " ('grade', 1.0): 4,\n",
       " ('al', 1.0): 4,\n",
       " ('grand', 1.0): 4,\n",
       " ('manila_bro', 1.0): 2,\n",
       " ('chosen', 1.0): 1,\n",
       " ('syazwanzain', 1.0): 1,\n",
       " ('let', 1.0): 91,\n",
       " ('around', 1.0): 17,\n",
       " ('..', 1.0): 128,\n",
       " ('side', 1.0): 16,\n",
       " ('world', 1.0): 27,\n",
       " ('eh', 1.0): 2,\n",
       " ('take', 1.0): 43,\n",
       " ('care', 1.0): 18,\n",
       " ('micha', 1.0): 1,\n",
       " ('1green', 1.0): 1,\n",
       " ('superninjaalan', 1.0): 1,\n",
       " ('doug_laney', 1.0): 1,\n",
       " ('final', 1.0): 30,\n",
       " ('fuck', 1.0): 26,\n",
       " ('weekend', 1.0): 76,\n",
       " ('real', 1.0): 21,\n",
       " ('lolesportspedia', 1.0): 1,\n",
       " ('x45', 1.0): 1,\n",
       " ('join', 1.0): 23,\n",
       " ('hushedcallwithfraydo', 1.0): 1,\n",
       " ('gift', 1.0): 8,\n",
       " ('_fraydo', 1.0): 1,\n",
       " ('hushedapp', 1.0): 3,\n",
       " ('yaslarri', 1.0): 1,\n",
       " ('yeahhh', 1.0): 1,\n",
       " ('hushedpinwithsammi', 1.0): 2,\n",
       " ('event', 1.0): 8,\n",
       " ('might', 1.0): 27,\n",
       " ('sammywilk', 1.0): 2,\n",
       " ('luv', 1.0): 6,\n",
       " ('realli', 1.0): 79,\n",
       " ('appreci', 1.0): 31,\n",
       " ('share', 1.0): 46,\n",
       " ('xhebenkewu', 1.0): 1,\n",
       " ('_9920', 1.0): 1,\n",
       " ('tompark', 1.0): 4,\n",
       " ('wow', 1.0): 22,\n",
       " ('tom', 1.0): 5,\n",
       " ('darlingixhai', 1.0): 1,\n",
       " ('22', 1.0): 7,\n",
       " ('syreenann', 1.0): 1,\n",
       " ('americanograin', 1.0): 1,\n",
       " ('pecomep', 1.0): 1,\n",
       " ('apaulicand', 1.0): 1,\n",
       " ('zaynzaynmalik', 1.0): 1,\n",
       " ('30', 1.0): 6,\n",
       " ('gym', 1.0): 4,\n",
       " ('monday', 1.0): 9,\n",
       " ('harnilizaloui', 1.0): 1,\n",
       " ('invit', 1.0): 17,\n",
       " ('scope', 1.0): 5,\n",
       " ('nude', 1.0): 2,\n",
       " ('jacobwhitesid', 1.0): 1,\n",
       " ('sleep', 1.0): 45,\n",
       " ('birthday', 1.0): 74,\n",
       " ('metalgear_jp', 1.0): 1,\n",
       " ('kojima_hideo', 1.0): 1,\n",
       " ('want', 1.0): 96,\n",
       " ('t-shirt', 1.0): 3,\n",
       " ('cool', 1.0): 38,\n",
       " ('axerad', 1.0): 1,\n",
       " ('haw', 1.0): 1,\n",
       " ('phela', 1.0): 1,\n",
       " ('mom', 1.0): 10,\n",
       " ('obviou', 1.0): 2,\n",
       " ('zaynmalik', 1.0): 4,\n",
       " ('princ', 1.0): 1,\n",
       " ('charm', 1.0): 1,\n",
       " ('stage', 1.0): 2,\n",
       " ('luck', 1.0): 30,\n",
       " ('straz_da', 1.0): 1,\n",
       " ('dcarsoncpa', 1.0): 1,\n",
       " ('gh813600', 1.0): 1,\n",
       " ('twentyonepilot', 1.0): 1,\n",
       " ('fujirock_jp', 1.0): 1,\n",
       " ('tyler', 1.0): 2,\n",
       " ('hipster', 1.0): 1,\n",
       " ('glass', 1.0): 5,\n",
       " ('martyrafenstein', 1.0): 1,\n",
       " ('marti', 1.0): 2,\n",
       " ('glad', 1.0): 43,\n",
       " ('ukbusinesslunch', 1.0): 1,\n",
       " ('lafitnessukhelp', 1.0): 1,\n",
       " ('done', 1.0): 54,\n",
       " ('afternoon', 1.0): 10,\n",
       " ('read', 1.0): 34,\n",
       " ('kahfi', 1.0): 1,\n",
       " ('finish', 1.0): 17,\n",
       " ('ohmyg', 1.0): 1,\n",
       " ('yaya', 1.0): 3,\n",
       " ('dub', 1.0): 2,\n",
       " ('mainedcm', 1.0): 1,\n",
       " ('stalk', 1.0): 2,\n",
       " ('ig', 1.0): 3,\n",
       " ('gondooo', 1.0): 1,\n",
       " ('moo', 1.0): 3,\n",
       " ('tologooo', 1.0): 1,\n",
       " ('rozbab', 1.0): 1,\n",
       " ('becom', 1.0): 10,\n",
       " ('detail', 1.0): 10,\n",
       " ('ngourd', 1.0): 1,\n",
       " ('locita', 1.0): 1,\n",
       " ('d_robert_kelli', 1.0): 1,\n",
       " ('kevinthewhippet', 1.0): 1,\n",
       " ('cassie_spaniel', 1.0): 1,\n",
       " ('bracken_nelson', 1.0): 1,\n",
       " ('bellisimobella', 1.0): 1,\n",
       " ('spanielharri', 1.0): 1,\n",
       " ('zzz', 1.0): 1,\n",
       " ('xx', 1.0): 42,\n",
       " ('physiotherapi', 1.0): 1,\n",
       " ('hashtag', 1.0): 5,\n",
       " ('cjlopez', 1.0): 1,\n",
       " ('21', 1.0): 12,\n",
       " ('üí™', 1.0): 1,\n",
       " ('monica', 1.0): 1,\n",
       " ('miss', 1.0): 27,\n",
       " ('sound', 1.0): 23,\n",
       " ('morn', 1.0): 101,\n",
       " ('x43', 1.0): 1,\n",
       " ('mandascapinello', 1.0): 1,\n",
       " ('definit', 1.0): 23,\n",
       " ('tri', 1.0): 44,\n",
       " ('tonight', 1.0): 22,\n",
       " ('took', 1.0): 8,\n",
       " ('advic', 1.0): 6,\n",
       " ('treviso', 1.0): 1,\n",
       " ('morallosanthoni', 1.0): 1,\n",
       " ('nikkieriozzi', 1.0): 1,\n",
       " ('impastel', 1.0): 17,\n",
       " ('concert', 1.0): 24,\n",
       " ('citi', 1.0): 27,\n",
       " ('countri', 1.0): 23,\n",
       " (\"i'll\", 1.0): 90,\n",
       " ('start', 1.0): 61,\n",
       " ('fine', 1.0): 10,\n",
       " ('gorgeou', 1.0): 12,\n",
       " ('xo', 1.0): 2,\n",
       " ('oven', 1.0): 3,\n",
       " ('roast', 1.0): 2,\n",
       " ('garlic', 1.0): 1,\n",
       " ('oliv', 1.0): 1,\n",
       " ('oil', 1.0): 4,\n",
       " ('dri', 1.0): 5,\n",
       " ('tomato', 1.0): 1,\n",
       " ('basil', 1.0): 1,\n",
       " ('centuri', 1.0): 1,\n",
       " ('tuna', 1.0): 1,\n",
       " ('hostmyoff', 1.0): 1,\n",
       " ('nigelpwhittak', 1.0): 1,\n",
       " ('lemezma', 1.0): 1,\n",
       " ('twbc_busi', 1.0): 2,\n",
       " ('_thebunkerjl', 1.0): 1,\n",
       " ('right', 1.0): 47,\n",
       " ('back', 1.0): 98,\n",
       " ('atchya', 1.0): 1,\n",
       " ('teamtal', 1.0): 1,\n",
       " ('17', 1.0): 7,\n",
       " ('flashhay', 1.0): 1,\n",
       " ('even', 1.0): 35,\n",
       " ('almost', 1.0): 10,\n",
       " ('michelploria', 1.0): 1,\n",
       " ('myfrenchc', 1.0): 1,\n",
       " ('jasoncr', 1.0): 1,\n",
       " ('chanc', 1.0): 6,\n",
       " ('chiab', 1.0): 1,\n",
       " ('2486', 1.0): 1,\n",
       " ('mrclivec', 1.0): 1,\n",
       " ('pcdkirkwood', 1.0): 1,\n",
       " ('dc_arvsgt', 1.0): 1,\n",
       " ('cops_presid', 1.0): 1,\n",
       " ('emwilliamscccu', 1.0): 1,\n",
       " ('laurargallagh', 1.0): 1,\n",
       " ('hall', 1.0): 3,\n",
       " ('11kate', 1.0): 1,\n",
       " ('laminx', 1.0): 1,\n",
       " ('541', 1.0): 1,\n",
       " ('johntarbet', 1.0): 1,\n",
       " ('71', 1.0): 4,\n",
       " ('cheer', 1.0): 20,\n",
       " ('thatguycalledp', 1.0): 1,\n",
       " ('po', 1.0): 4,\n",
       " ('ice', 1.0): 6,\n",
       " ('cream', 1.0): 6,\n",
       " ('19strawberry66', 1.0): 2,\n",
       " ('agr', 1.0): 16,\n",
       " ('100', 1.0): 8,\n",
       " ('spazzytsukihara', 1.0): 5,\n",
       " ('heheheh', 1.0): 2,\n",
       " ('point', 1.0): 13,\n",
       " ('stay', 1.0): 25,\n",
       " ('home', 1.0): 31,\n",
       " ('digitalplac', 1.0): 1,\n",
       " ('2be', 1.0): 1,\n",
       " ('intlboost', 1.0): 1,\n",
       " ('_lafontpress', 1.0): 1,\n",
       " ('stayfaboo', 1.0): 1,\n",
       " ('soon', 1.0): 47,\n",
       " ('promi', 1.0): 6,\n",
       " ('web', 1.0): 4,\n",
       " ('whatsapp', 1.0): 5,\n",
       " ('volta', 1.0): 1,\n",
       " ('funcionar', 1.0): 1,\n",
       " ('com', 1.0): 2,\n",
       " ('iphon', 1.0): 7,\n",
       " ('jailbroken', 1.0): 1,\n",
       " ('crustyolddeen', 1.0): 2,\n",
       " ('later', 1.0): 16,\n",
       " ('34', 1.0): 5,\n",
       " ('min', 1.0): 10,\n",
       " ('leia', 1.0): 1,\n",
       " ('appear', 1.0): 3,\n",
       " ('hologram', 1.0): 1,\n",
       " ('r2d2', 1.0): 1,\n",
       " ('w', 1.0): 18,\n",
       " ('messag', 1.0): 10,\n",
       " ('obi', 1.0): 1,\n",
       " ('wan', 1.0): 3,\n",
       " ('sit', 1.0): 8,\n",
       " ('luke', 1.0): 7,\n",
       " ('mburu', 1.0): 1,\n",
       " ('__', 1.0): 7,\n",
       " ('inter', 1.0): 2,\n",
       " ('ucl', 1.0): 1,\n",
       " ('arsen', 1.0): 3,\n",
       " ('small', 1.0): 4,\n",
       " ('team', 1.0): 30,\n",
       " ('pass', 1.0): 12,\n",
       " ('üöÇ', 1.0): 1,\n",
       " ('dewsburi', 1.0): 2,\n",
       " ('railway', 1.0): 1,\n",
       " ('station', 1.0): 4,\n",
       " ('dew', 1.0): 1,\n",
       " ('nationalrailenq', 1.0): 1,\n",
       " ('west', 1.0): 3,\n",
       " ('yorkshir', 1.0): 2,\n",
       " ('clearlyarticl', 1.0): 1,\n",
       " ('430', 1.0): 1,\n",
       " ('smh', 1.0): 2,\n",
       " ('uptommosass', 1.0): 1,\n",
       " ('9:25', 1.0): 1,\n",
       " ('live', 1.0): 26,\n",
       " ('strang', 1.0): 4,\n",
       " ('imagin', 1.0): 5,\n",
       " ('megan', 1.0): 2,\n",
       " ('bookmyshow', 1.0): 3,\n",
       " ('masaantoday', 1.0): 6,\n",
       " ('a4', 1.0): 3,\n",
       " ('shweta', 1.0): 1,\n",
       " ('tripathi', 1.0): 1,\n",
       " ('wforwoman', 1.0): 10,\n",
       " ('5', 1.0): 22,\n",
       " ('20', 1.0): 10,\n",
       " ('kurta', 1.0): 3,\n",
       " ('half', 1.0): 7,\n",
       " ('number', 1.0): 13,\n",
       " ('wsalelov', 1.0): 16,\n",
       " ('ah', 1.0): 13,\n",
       " ('larri', 1.0): 3,\n",
       " ('transworldbook', 1.0): 1,\n",
       " ('anyway', 1.0): 16,\n",
       " ('kinda', 1.0): 13,\n",
       " ('goood', 1.0): 4,\n",
       " ('jhun_hunyo', 1.0): 1,\n",
       " ('life', 1.0): 49,\n",
       " ('enn', 1.0): 1,\n",
       " ('ojbj', 1.0): 1,\n",
       " ('holmesjsamuel', 1.0): 1,\n",
       " ('could', 1.0): 32,\n",
       " ('warmup', 1.0): 1,\n",
       " ('15th', 1.0): 2,\n",
       " ('bath', 1.0): 7,\n",
       " ('dum', 1.0): 2,\n",
       " ('andar', 1.0): 1,\n",
       " ('ram', 1.0): 1,\n",
       " ('sampath', 1.0): 1,\n",
       " ('sona', 1.0): 1,\n",
       " ('mohapatra', 1.0): 1,\n",
       " ('samantha', 1.0): 1,\n",
       " ('edward', 1.0): 1,\n",
       " ('mein', 1.0): 1,\n",
       " ('tulan', 1.0): 1,\n",
       " ('razi', 1.0): 2,\n",
       " ('wah', 1.0): 2,\n",
       " ('josh', 1.0): 1,\n",
       " ('justinbieb', 1.0): 9,\n",
       " ('alway', 1.0): 67,\n",
       " ('smile', 1.0): 62,\n",
       " ('darlakim', 1.0): 1,\n",
       " ('pictur', 1.0): 12,\n",
       " ('arsenalnewsasit', 1.0): 3,\n",
       " ('16.20', 1.0): 1,\n",
       " ('izywaylesexpat', 1.0): 1,\n",
       " ('na4innov', 1.0): 1,\n",
       " ('inxpresscoazur', 1.0): 1,\n",
       " ('juleeyaanaa', 1.0): 1,\n",
       " ('giveitup', 1.0): 1,\n",
       " ('given', 1.0): 3,\n",
       " ('ga', 1.0): 3,\n",
       " ('subsidi', 1.0): 1,\n",
       " ('initi', 1.0): 4,\n",
       " ('propo', 1.0): 3,\n",
       " ('delight', 1.0): 7,\n",
       " ('dayloladay', 1.0): 1,\n",
       " ('yesterday', 1.0): 8,\n",
       " ('x42', 1.0): 1,\n",
       " ('jaimeemelani', 1.0): 1,\n",
       " ('lmaoo', 1.0): 2,\n",
       " ('song', 1.0): 22,\n",
       " ('ever', 1.0): 23,\n",
       " ('shall', 1.0): 6,\n",
       " ('littl', 1.0): 31,\n",
       " ('throwback', 1.0): 3,\n",
       " ('clazziebritcha', 1.0): 1,\n",
       " ('outli', 1.0): 1,\n",
       " ('island', 1.0): 5,\n",
       " ('cheung', 1.0): 1,\n",
       " ('chau', 1.0): 1,\n",
       " ('mui', 1.0): 1,\n",
       " ('wo', 1.0): 1,\n",
       " ('total', 1.0): 9,\n",
       " ('differ', 1.0): 11,\n",
       " ('kfckitchentour', 1.0): 2,\n",
       " ('kitchen', 1.0): 4,\n",
       " ('clean', 1.0): 2,\n",
       " (\"i'm\", 1.0): 183,\n",
       " ('kfc_india', 1.0): 2,\n",
       " ('cybelxxx', 1.0): 1,\n",
       " ('jana', 1.0): 1,\n",
       " ('7380', 1.0): 1,\n",
       " ('cusp', 1.0): 1,\n",
       " ('test', 1.0): 7,\n",
       " ('water', 1.0): 8,\n",
       " ('reward', 1.0): 1,\n",
       " ('broadcastbeat', 1.0): 1,\n",
       " ('insunwetrust', 1.0): 1,\n",
       " ('conseilsmkg', 1.0): 1,\n",
       " ('arummzz', 1.0): 2,\n",
       " ('drive', 1.0): 11,\n",
       " ('travel', 1.0): 20,\n",
       " ('yogyakarta', 1.0): 3,\n",
       " ('jeep', 1.0): 3,\n",
       " ('indonesia', 1.0): 4,\n",
       " ('instamood', 1.0): 3,\n",
       " ('wanna', 1.0): 30,\n",
       " ('skype', 1.0): 3,\n",
       " ('agylyxa', 1.0): 1,\n",
       " ('may', 1.0): 22,\n",
       " ('nice', 1.0): 98,\n",
       " ('friendli', 1.0): 2,\n",
       " ('pretend', 1.0): 2,\n",
       " ('film', 1.0): 9,\n",
       " ('congratul', 1.0): 15,\n",
       " ('amisharanka', 1.0): 1,\n",
       " ('95', 1.0): 3,\n",
       " ('winner', 1.0): 4,\n",
       " ('cheesydelight', 1.0): 1,\n",
       " ('contest', 1.0): 6,\n",
       " ('address', 1.0): 10,\n",
       " ('guy', 1.0): 60,\n",
       " ('clararojasg', 1.0): 1,\n",
       " ('bf_p', 1.0): 1,\n",
       " ('2c', 1.0): 1,\n",
       " ('mybusiness_plan', 1.0): 1,\n",
       " ('puamagasiva', 1.0): 1,\n",
       " ('market', 1.0): 5,\n",
       " ('24/7', 1.0): 1,\n",
       " ('vineshpom', 1.0): 1,\n",
       " ('14', 1.0): 6,\n",
       " ('hour', 1.0): 27,\n",
       " ('leav', 1.0): 12,\n",
       " ('without', 1.0): 12,\n",
       " ('delay', 1.0): 2,\n",
       " ('actual', 1.0): 19,\n",
       " ('easi', 1.0): 9,\n",
       " ('guess', 1.0): 14,\n",
       " ('train', 1.0): 10,\n",
       " ('wd', 1.0): 1,\n",
       " ('shift', 1.0): 5,\n",
       " ('engin', 1.0): 2,\n",
       " ('etc', 1.0): 2,\n",
       " ('sunburn', 1.0): 1,\n",
       " ('peel', 1.0): 2,\n",
       " ('sexdate_grati', 1.0): 1,\n",
       " ('blog', 1.0): 31,\n",
       " ('tikosd', 1.0): 1,\n",
       " ('no1_razorstan', 1.0): 1,\n",
       " ('cassthetrain', 1.0): 1,\n",
       " ('huge', 1.0): 11,\n",
       " ('warm', 1.0): 6,\n",
       " ('vodkablond', 1.0): 2,\n",
       " ('‚òÜ', 1.0): 3,\n",
       " ('complet', 1.0): 11,\n",
       " ('triangl', 1.0): 2,\n",
       " ('luciennediv', 1.0): 1,\n",
       " ('northern', 1.0): 1,\n",
       " ('ireland', 1.0): 2,\n",
       " ('sight', 1.0): 1,\n",
       " ('mecastor', 1.0): 1,\n",
       " ('01mica', 1.0): 1,\n",
       " ('z_intl_ag', 1.0): 1,\n",
       " ('tivipro', 1.0): 1,\n",
       " ('compexli', 1.0): 1,\n",
       " ('imraina', 1.0): 1,\n",
       " ('smthng', 1.0): 2,\n",
       " ('fr', 1.0): 3,\n",
       " ('hug', 1.0): 13,\n",
       " ('xoxo', 1.0): 3,\n",
       " ('uu', 1.0): 1,\n",
       " ('jaann', 1.0): 1,\n",
       " ('topnewfollow', 1.0): 2,\n",
       " ('bestofficpad', 1.0): 1,\n",
       " ('mrcfluegel', 1.0): 1,\n",
       " ('jeanmarcpn', 1.0): 1,\n",
       " ('connect', 1.0): 14,\n",
       " ('mooseallain', 1.0): 1,\n",
       " ('meatbingo', 1.0): 4,\n",
       " ('wonder', 1.0): 35,\n",
       " ('made', 1.0): 53,\n",
       " ('fluffi', 1.0): 1,\n",
       " ('insid', 1.0): 8,\n",
       " ('pirouett', 1.0): 1,\n",
       " ('kristophcajon', 1.0): 1,\n",
       " ('trip', 1.0): 14,\n",
       " ('philli', 1.0): 1,\n",
       " ('decemb', 1.0): 3,\n",
       " (\"i'd\", 1.0): 20,\n",
       " ('dude', 1.0): 7,\n",
       " ('x41', 1.0): 1,\n",
       " ('question', 1.0): 17,\n",
       " ('flaw', 1.0): 1,\n",
       " ('pain', 1.0): 9,\n",
       " ('negat', 1.0): 1,\n",
       " ('strength', 1.0): 3,\n",
       " ('reflectkn', 1.0): 1,\n",
       " ('went', 1.0): 12,\n",
       " ('solo', 1.0): 4,\n",
       " ('move', 1.0): 12,\n",
       " ('fav', 1.0): 13,\n",
       " ('nirvana', 1.0): 1,\n",
       " ('smell', 1.0): 2,\n",
       " ('teen', 1.0): 3,\n",
       " ('spirit', 1.0): 3,\n",
       " ('rip', 1.0): 3,\n",
       " ('ami', 1.0): 5,\n",
       " ('wineh', 1.0): 1,\n",
       " ('ccidelyon', 1.0): 1,\n",
       " ('cci', 1.0): 3,\n",
       " ('_95', 1.0): 1,\n",
       " ('cpneri_esigroup', 1.0): 1,\n",
       " ('coupl', 1.0): 9,\n",
       " ('tomhiddleston', 1.0): 1,\n",
       " ('elizabetholsen', 1.0): 1,\n",
       " ('yaytheylookgreat', 1.0): 1,\n",
       " ('goodnight', 1.0): 24,\n",
       " ('vid', 1.0): 11,\n",
       " ('wake', 1.0): 12,\n",
       " ('gonna', 1.0): 21,\n",
       " ('shoot', 1.0): 6,\n",
       " ('narakubrock', 1.0): 1,\n",
       " ('itti', 1.0): 2,\n",
       " ('bitti', 1.0): 2,\n",
       " ('teeni', 1.0): 2,\n",
       " ('bikini', 1.0): 3,\n",
       " ('much', 1.0): 89,\n",
       " ('4th', 1.0): 4,\n",
       " ('togeth', 1.0): 7,\n",
       " ('end', 1.0): 20,\n",
       " ('xfile', 1.0): 1,\n",
       " ('content', 1.0): 4,\n",
       " ('aangelayap', 1.0): 1,\n",
       " ('nttownend', 1.0): 1,\n",
       " ('rain', 1.0): 21,\n",
       " ('reyesfraulein', 1.0): 1,\n",
       " ('fatpunkstudio', 1.0): 1,\n",
       " ('fabul', 1.0): 5,\n",
       " ('fantast', 1.0): 13,\n",
       " ('caitecat', 1.0): 1,\n",
       " ('1209', 1.0): 1,\n",
       " ('‚ô°', 1.0): 20,\n",
       " ('jb', 1.0): 1,\n",
       " ('forev', 1.0): 5,\n",
       " ('belieb', 1.0): 3,\n",
       " ('diplomix', 1.0): 1,\n",
       " ('cci_entrepri', 1.0): 1,\n",
       " ('_92', 1.0): 2,\n",
       " ('franchiseedsuk', 1.0): 2,\n",
       " ('lusciouslynd', 1.0): 2,\n",
       " ('nighti', 1.0): 1,\n",
       " ('bug', 1.0): 3,\n",
       " ('bite', 1.0): 1,\n",
       " ('bonsplansblog', 1.0): 1,\n",
       " ('bracelet', 1.0): 2,\n",
       " ('idea', 1.0): 26,\n",
       " ('guywilliamsguy', 1.0): 1,\n",
       " ('foundri', 1.0): 1,\n",
       " ('game', 1.0): 27,\n",
       " ('suzannep', 1.0): 1,\n",
       " ('kevinbacon', 1.0): 1,\n",
       " ('katosman', 1.0): 1,\n",
       " ('sen', 1.0): 7,\n",
       " ('pic', 1.0): 27,\n",
       " ('ef', 1.0): 1,\n",
       " ('phone', 1.0): 19,\n",
       " ('woot', 1.0): 2,\n",
       " ('derek_gta', 1.0): 1,\n",
       " ('derek', 1.0): 1,\n",
       " ('use', 1.0): 44,\n",
       " ('parkshar', 1.0): 1,\n",
       " ('gloucestershir', 1.0): 1,\n",
       " ('aaahhh', 1.0): 2,\n",
       " ('man', 1.0): 24,\n",
       " ('traffic', 1.0): 2,\n",
       " ('stress', 1.0): 8,\n",
       " ('reliev', 1.0): 1,\n",
       " ('elev', 1.0): 2,\n",
       " ('joussotfrench_j', 1.0): 1,\n",
       " ('nyibf', 1.0): 1,\n",
       " ('el1new', 1.0): 1,\n",
       " (\"how'r\", 1.0): 1,\n",
       " ('jesutomisin', 1.0): 1,\n",
       " ('arbeloa', 1.0): 1,\n",
       " ('shawnmend', 1.0): 1,\n",
       " ('turn', 1.0): 15,\n",
       " ('omg', 1.0): 15,\n",
       " ('matteomeacci', 1.0): 1,\n",
       " ('say', 1.0): 61,\n",
       " ('europ', 1.0): 1,\n",
       " ('rise', 1.0): 2,\n",
       " ('find', 1.0): 23,\n",
       " ('hard', 1.0): 12,\n",
       " ('believ', 1.0): 9,\n",
       " ('uncount', 1.0): 1,\n",
       " ('coz', 1.0): 3,\n",
       " ('unlimit', 1.0): 1,\n",
       " ('cour', 1.0): 18,\n",
       " ('teamposit', 1.0): 1,\n",
       " ('aldub', 1.0): 2,\n",
       " ('coffeebreak', 1.0): 1,\n",
       " ('laurenarren', 1.0): 1,\n",
       " ('drparkav', 1.0): 1,\n",
       " ('jwkanyuira', 1.0): 1,\n",
       " ('1969', 1.0): 2,\n",
       " ('dherac', 1.0): 1,\n",
       " ('rhoachri', 1.0): 1,\n",
       " ('barbarabathurst', 1.0): 1,\n",
       " ('1cryingey', 1.0): 1,\n",
       " ('willisteam', 1.0): 1,\n",
       " ('‚òï', 1.0): 3,\n",
       " ('rita', 1.0): 2,\n",
       " ('mikerobb', 1.0): 1,\n",
       " ('info', 1.0): 13,\n",
       " (\"we'd\", 1.0): 4,\n",
       " ('24gooch', 1.0): 1,\n",
       " ('way', 1.0): 46,\n",
       " ('boy', 1.0): 21,\n",
       " ('graphur', 1.0): 2,\n",
       " ('x40', 1.0): 1,\n",
       " ('acbm_secem', 1.0): 1,\n",
       " ('dcarsoncpa_nyc', 1.0): 1,\n",
       " ('promosalonsinfo', 1.0): 1,\n",
       " ('true', 1.0): 22,\n",
       " ('zarlashtfai', 1.0): 1,\n",
       " ('tabinda_samar', 1.0): 2,\n",
       " ('sethi', 1.0): 2,\n",
       " ('high', 1.0): 7,\n",
       " ('iam_lennox', 1.0): 1,\n",
       " ('exe', 1.0): 1,\n",
       " ('skeem', 1.0): 1,\n",
       " ('saam', 1.0): 1,\n",
       " ('peopl', 1.0): 51,\n",
       " ('_pumpchkin_', 1.0): 1,\n",
       " ...}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcc768c",
   "metadata": {},
   "source": [
    "Some words are repeated in both + and - tweets. As an example see the word ***happi*** from below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7bdd4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times the word happy is appeared in a positive tweet is 211\n",
      "Number of times the word happy is appeared in a positive tweet is 25\n"
     ]
    }
   ],
   "source": [
    "print('Number of times the word happy is appeared in a positive tweet is', \n",
    "      freqs.get(('happi', 1)))\n",
    "print('Number of times the word happy is appeared in a positive tweet is', \n",
    "      freqs.get(('happi', 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46821127",
   "metadata": {},
   "source": [
    "### Piece of Mind\n",
    "Here the goal was to count the frequency of words in positive and negative tweets. If we are give a tweet, how can we know that how many times the words were repeated in a + tweet or a - tweet?\n",
    "\n",
    "    The answer is simple. We get the tweet and compare it with the frequecy dictionary which is built in Step 4\n",
    "    \n",
    "as an example ***sample_tweet*** is taken, processed and the + and - freqeuncies are found for each of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b26cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample tweet is:\n",
      " *sigh* \"@Whykaysbeauty: Bruhhh‚Äú@Dopjones: Call me daddy one more time :)‚Äù\"\n",
      "\n",
      "The processed tweet is:\n",
      " ['sigh', 'whykaysbeauti', 'bruhhh', '‚Äú', 'dopjon', 'call', 'daddi', 'one', 'time', ':)', '‚Äù']\n"
     ]
    }
   ],
   "source": [
    "print('The sample tweet is:\\n', sample_tweet)\n",
    "sample_tweet = twts[999]\n",
    "\n",
    "# processed tweet\n",
    "proc_twt = process_tweet(sample_tweet)\n",
    "print('\\nThe processed tweet is:\\n', proc_twt)\n",
    "\n",
    "dic_words = []\n",
    "\n",
    "for word in proc_twt:\n",
    "    \n",
    "    pos = 0;\n",
    "    neg = 0;\n",
    "    \n",
    "    # capture the frequency value of the positive word\n",
    "    if (word, 1) in freqs:\n",
    "        pos = freqs[(word, 1)]\n",
    "        \n",
    "    # capture the frequency value of the negative word\n",
    "    if (word, 0) in freqs:\n",
    "        neg = freqs[(word,0)]\n",
    "    \n",
    "    # the dic_words shows the number times the word appears as positive and negative\n",
    "    dic_words.append( [word, pos, neg] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb6b5b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the frequency of each words in the tweet which appears in a positive and negative tweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['sigh', 3, 13],\n",
       " ['whykaysbeauti', 1, 0],\n",
       " ['bruhhh', 1, 0],\n",
       " ['‚Äú', 7, 15],\n",
       " ['dopjon', 1, 0],\n",
       " ['call', 37, 29],\n",
       " ['daddi', 2, 4],\n",
       " ['one', 129, 150],\n",
       " ['time', 127, 166],\n",
       " [':)', 3568, 2],\n",
       " ['‚Äù', 5, 11]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nHere is the frequency of each words in the tweet which appears in a positive and negative tweets')\n",
    "dic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d936a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
